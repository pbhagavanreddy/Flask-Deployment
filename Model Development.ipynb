{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris = iris.drop(columns='Id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('Species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 1s 11ms/sample - loss: 1.0870 - acc: 0.3250 - val_loss: 1.1014 - val_acc: 0.3667\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.0854 - acc: 0.3250 - val_loss: 1.0996 - val_acc: 0.3667\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0837 - acc: 0.3250 - val_loss: 1.0982 - val_acc: 0.3667\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0821 - acc: 0.3250 - val_loss: 1.0969 - val_acc: 0.3667\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0805 - acc: 0.3250 - val_loss: 1.0957 - val_acc: 0.3667\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0790 - acc: 0.3250 - val_loss: 1.0943 - val_acc: 0.3667\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0776 - acc: 0.3250 - val_loss: 1.0930 - val_acc: 0.3667\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0762 - acc: 0.3250 - val_loss: 1.0915 - val_acc: 0.3667\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0746 - acc: 0.3250 - val_loss: 1.0902 - val_acc: 0.4000\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0732 - acc: 0.3250 - val_loss: 1.0889 - val_acc: 0.4000\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0716 - acc: 0.3250 - val_loss: 1.0876 - val_acc: 0.4000\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0702 - acc: 0.3250 - val_loss: 1.0863 - val_acc: 0.4000\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0686 - acc: 0.3250 - val_loss: 1.0850 - val_acc: 0.4000\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 1.0672 - acc: 0.3250 - val_loss: 1.0837 - val_acc: 0.4000\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0656 - acc: 0.3250 - val_loss: 1.0825 - val_acc: 0.4000\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0641 - acc: 0.3250 - val_loss: 1.0814 - val_acc: 0.4000\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.0625 - acc: 0.3250 - val_loss: 1.0802 - val_acc: 0.4000\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0609 - acc: 0.3250 - val_loss: 1.0790 - val_acc: 0.4000\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 1.0592 - acc: 0.3250 - val_loss: 1.0779 - val_acc: 0.4000\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.0575 - acc: 0.3250 - val_loss: 1.0767 - val_acc: 0.4000\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0558 - acc: 0.3250 - val_loss: 1.0756 - val_acc: 0.4000\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0540 - acc: 0.3250 - val_loss: 1.0742 - val_acc: 0.4000\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0521 - acc: 0.3250 - val_loss: 1.0729 - val_acc: 0.4000\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0503 - acc: 0.3250 - val_loss: 1.0715 - val_acc: 0.4000\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 1.0483 - acc: 0.3250 - val_loss: 1.0700 - val_acc: 0.4000\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0464 - acc: 0.3250 - val_loss: 1.0686 - val_acc: 0.4000\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0444 - acc: 0.3250 - val_loss: 1.0672 - val_acc: 0.4000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.0423 - acc: 0.3250 - val_loss: 1.0657 - val_acc: 0.4000\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.0401 - acc: 0.3500 - val_loss: 1.0640 - val_acc: 0.4000\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0380 - acc: 0.3583 - val_loss: 1.0625 - val_acc: 0.4000\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.0358 - acc: 0.3750 - val_loss: 1.0609 - val_acc: 0.4000\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.0335 - acc: 0.4167 - val_loss: 1.0593 - val_acc: 0.4333\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 1.0312 - acc: 0.4333 - val_loss: 1.0577 - val_acc: 0.4333\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0288 - acc: 0.4833 - val_loss: 1.0560 - val_acc: 0.4667\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0264 - acc: 0.5167 - val_loss: 1.0543 - val_acc: 0.4667\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0240 - acc: 0.5750 - val_loss: 1.0525 - val_acc: 0.5333\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.0215 - acc: 0.5833 - val_loss: 1.0507 - val_acc: 0.5333\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 1.0188 - acc: 0.6167 - val_loss: 1.0488 - val_acc: 0.5333\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0163 - acc: 0.6500 - val_loss: 1.0470 - val_acc: 0.5667\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0136 - acc: 0.6667 - val_loss: 1.0449 - val_acc: 0.5667\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.0108 - acc: 0.6667 - val_loss: 1.0429 - val_acc: 0.5667\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0081 - acc: 0.6833 - val_loss: 1.0407 - val_acc: 0.6000\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 1.0052 - acc: 0.6833 - val_loss: 1.0385 - val_acc: 0.6000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.0023 - acc: 0.6833 - val_loss: 1.0362 - val_acc: 0.6000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.9994 - acc: 0.6833 - val_loss: 1.0340 - val_acc: 0.6000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.9963 - acc: 0.6833 - val_loss: 1.0314 - val_acc: 0.6000\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9934 - acc: 0.6833 - val_loss: 1.0291 - val_acc: 0.6000\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9901 - acc: 0.6833 - val_loss: 1.0265 - val_acc: 0.6000\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.9870 - acc: 0.6833 - val_loss: 1.0241 - val_acc: 0.6000\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9837 - acc: 0.6833 - val_loss: 1.0214 - val_acc: 0.6000\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9805 - acc: 0.6833 - val_loss: 1.0190 - val_acc: 0.6000\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9772 - acc: 0.6833 - val_loss: 1.0165 - val_acc: 0.6000\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9736 - acc: 0.6833 - val_loss: 1.0137 - val_acc: 0.6000\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9703 - acc: 0.6833 - val_loss: 1.0110 - val_acc: 0.6000\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.9667 - acc: 0.6833 - val_loss: 1.0081 - val_acc: 0.6000\n",
      "Epoch 56/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9633 - acc: 0.6833 - val_loss: 1.0051 - val_acc: 0.6000\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9597 - acc: 0.6833 - val_loss: 1.0022 - val_acc: 0.6000\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9561 - acc: 0.6833 - val_loss: 0.9992 - val_acc: 0.6000\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9524 - acc: 0.6833 - val_loss: 0.9961 - val_acc: 0.6000\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9488 - acc: 0.6833 - val_loss: 0.9930 - val_acc: 0.6000\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9450 - acc: 0.6833 - val_loss: 0.9897 - val_acc: 0.6000\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9413 - acc: 0.6833 - val_loss: 0.9864 - val_acc: 0.6000\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9376 - acc: 0.6833 - val_loss: 0.9833 - val_acc: 0.6000\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9338 - acc: 0.6833 - val_loss: 0.9802 - val_acc: 0.6000\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9300 - acc: 0.6833 - val_loss: 0.9773 - val_acc: 0.6000\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9262 - acc: 0.6833 - val_loss: 0.9742 - val_acc: 0.6000\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9224 - acc: 0.6833 - val_loss: 0.9711 - val_acc: 0.6000\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.9186 - acc: 0.6833 - val_loss: 0.9681 - val_acc: 0.6000\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9144 - acc: 0.6833 - val_loss: 0.9646 - val_acc: 0.6000\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9106 - acc: 0.6833 - val_loss: 0.9614 - val_acc: 0.6000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9067 - acc: 0.6833 - val_loss: 0.9581 - val_acc: 0.6000\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9026 - acc: 0.6833 - val_loss: 0.9548 - val_acc: 0.6000\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8987 - acc: 0.6833 - val_loss: 0.9515 - val_acc: 0.6000\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8947 - acc: 0.6833 - val_loss: 0.9482 - val_acc: 0.6000\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8906 - acc: 0.6833 - val_loss: 0.9448 - val_acc: 0.6000\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8756 - acc: 0.687 - 0s 108us/sample - loss: 0.8866 - acc: 0.6833 - val_loss: 0.9414 - val_acc: 0.6000\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8825 - acc: 0.6833 - val_loss: 0.9379 - val_acc: 0.6000\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8785 - acc: 0.6833 - val_loss: 0.9345 - val_acc: 0.6000\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8742 - acc: 0.6833 - val_loss: 0.9309 - val_acc: 0.6000\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8702 - acc: 0.6833 - val_loss: 0.9274 - val_acc: 0.6000\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8661 - acc: 0.6833 - val_loss: 0.9239 - val_acc: 0.6000\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8619 - acc: 0.6833 - val_loss: 0.9205 - val_acc: 0.6000\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8578 - acc: 0.6833 - val_loss: 0.9170 - val_acc: 0.6000\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8535 - acc: 0.6833 - val_loss: 0.9134 - val_acc: 0.6000\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8495 - acc: 0.6833 - val_loss: 0.9100 - val_acc: 0.6000\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8452 - acc: 0.6833 - val_loss: 0.9064 - val_acc: 0.6000\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8410 - acc: 0.6917 - val_loss: 0.9027 - val_acc: 0.6000\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8368 - acc: 0.6917 - val_loss: 0.8990 - val_acc: 0.6000\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8326 - acc: 0.6917 - val_loss: 0.8954 - val_acc: 0.6000\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8284 - acc: 0.6917 - val_loss: 0.8918 - val_acc: 0.6000\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8242 - acc: 0.6917 - val_loss: 0.8882 - val_acc: 0.6000\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8200 - acc: 0.6917 - val_loss: 0.8848 - val_acc: 0.6000\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8158 - acc: 0.6917 - val_loss: 0.8813 - val_acc: 0.6000\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8115 - acc: 0.6917 - val_loss: 0.8776 - val_acc: 0.6000\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8073 - acc: 0.7000 - val_loss: 0.8740 - val_acc: 0.6000\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8031 - acc: 0.7000 - val_loss: 0.8704 - val_acc: 0.6000\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7990 - acc: 0.7000 - val_loss: 0.8667 - val_acc: 0.6000\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7947 - acc: 0.7000 - val_loss: 0.8632 - val_acc: 0.6000\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.7906 - acc: 0.7000 - val_loss: 0.8596 - val_acc: 0.6000\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7863 - acc: 0.7000 - val_loss: 0.8559 - val_acc: 0.6000\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7822 - acc: 0.7000 - val_loss: 0.8522 - val_acc: 0.6000\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.7781 - acc: 0.7000 - val_loss: 0.8486 - val_acc: 0.6000\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7739 - acc: 0.7000 - val_loss: 0.8449 - val_acc: 0.6000\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.7699 - acc: 0.7000 - val_loss: 0.8415 - val_acc: 0.6000\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.7657 - acc: 0.7083 - val_loss: 0.8378 - val_acc: 0.6000\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7616 - acc: 0.7083 - val_loss: 0.8343 - val_acc: 0.6000\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7575 - acc: 0.7083 - val_loss: 0.8308 - val_acc: 0.6000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7535 - acc: 0.7083 - val_loss: 0.8274 - val_acc: 0.6000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.7494 - acc: 0.7167 - val_loss: 0.8239 - val_acc: 0.6000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7454 - acc: 0.7167 - val_loss: 0.8205 - val_acc: 0.6000\n",
      "Epoch 111/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7414 - acc: 0.7167 - val_loss: 0.8171 - val_acc: 0.6000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.7374 - acc: 0.7167 - val_loss: 0.8136 - val_acc: 0.6000\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7334 - acc: 0.7167 - val_loss: 0.8102 - val_acc: 0.6000\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.7294 - acc: 0.7167 - val_loss: 0.8067 - val_acc: 0.6000\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7256 - acc: 0.7167 - val_loss: 0.8033 - val_acc: 0.6000\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7216 - acc: 0.7167 - val_loss: 0.7999 - val_acc: 0.6000\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.7177 - acc: 0.7167 - val_loss: 0.7965 - val_acc: 0.6000\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7139 - acc: 0.7167 - val_loss: 0.7932 - val_acc: 0.6000\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7101 - acc: 0.7167 - val_loss: 0.7898 - val_acc: 0.6000\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7063 - acc: 0.7167 - val_loss: 0.7864 - val_acc: 0.6000\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.7024 - acc: 0.7167 - val_loss: 0.7832 - val_acc: 0.6000\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6987 - acc: 0.7167 - val_loss: 0.7801 - val_acc: 0.6000\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.6950 - acc: 0.7167 - val_loss: 0.7769 - val_acc: 0.6000\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.6912 - acc: 0.7167 - val_loss: 0.7737 - val_acc: 0.6000\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6875 - acc: 0.7167 - val_loss: 0.7704 - val_acc: 0.6000\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6839 - acc: 0.7167 - val_loss: 0.7671 - val_acc: 0.6000\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6803 - acc: 0.7167 - val_loss: 0.7641 - val_acc: 0.6000\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.6767 - acc: 0.7167 - val_loss: 0.7612 - val_acc: 0.6000\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.6732 - acc: 0.7167 - val_loss: 0.7583 - val_acc: 0.6000\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.6696 - acc: 0.7167 - val_loss: 0.7553 - val_acc: 0.6000\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6660 - acc: 0.7167 - val_loss: 0.7522 - val_acc: 0.6000\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6626 - acc: 0.7167 - val_loss: 0.7491 - val_acc: 0.6333\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6592 - acc: 0.7167 - val_loss: 0.7460 - val_acc: 0.6333\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6557 - acc: 0.7250 - val_loss: 0.7429 - val_acc: 0.6333\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6523 - acc: 0.7250 - val_loss: 0.7400 - val_acc: 0.6333\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6490 - acc: 0.7333 - val_loss: 0.7372 - val_acc: 0.6333\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6456 - acc: 0.7333 - val_loss: 0.7343 - val_acc: 0.6333\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6423 - acc: 0.7333 - val_loss: 0.7314 - val_acc: 0.6333\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6391 - acc: 0.7417 - val_loss: 0.7286 - val_acc: 0.6333\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.6358 - acc: 0.7417 - val_loss: 0.7258 - val_acc: 0.6333\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6327 - acc: 0.7417 - val_loss: 0.7231 - val_acc: 0.6333\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.6295 - acc: 0.7333 - val_loss: 0.7205 - val_acc: 0.6333\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6263 - acc: 0.7417 - val_loss: 0.7176 - val_acc: 0.6333\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6232 - acc: 0.7417 - val_loss: 0.7148 - val_acc: 0.6333\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6201 - acc: 0.7417 - val_loss: 0.7121 - val_acc: 0.6333\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6171 - acc: 0.7417 - val_loss: 0.7094 - val_acc: 0.6333\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6140 - acc: 0.7417 - val_loss: 0.7068 - val_acc: 0.6333\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6111 - acc: 0.7417 - val_loss: 0.7042 - val_acc: 0.6333\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6081 - acc: 0.7417 - val_loss: 0.7016 - val_acc: 0.6333\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6051 - acc: 0.7500 - val_loss: 0.6991 - val_acc: 0.6333\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6023 - acc: 0.7500 - val_loss: 0.6966 - val_acc: 0.6333\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5994 - acc: 0.7500 - val_loss: 0.6941 - val_acc: 0.6333\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5966 - acc: 0.7500 - val_loss: 0.6916 - val_acc: 0.6333\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5937 - acc: 0.7583 - val_loss: 0.6891 - val_acc: 0.6333\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5911 - acc: 0.7583 - val_loss: 0.6865 - val_acc: 0.6333\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.5882 - acc: 0.7583 - val_loss: 0.6841 - val_acc: 0.6333\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.5855 - acc: 0.7583 - val_loss: 0.6817 - val_acc: 0.6333\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5828 - acc: 0.7583 - val_loss: 0.6794 - val_acc: 0.6333\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.5801 - acc: 0.7583 - val_loss: 0.6771 - val_acc: 0.6333\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5775 - acc: 0.7583 - val_loss: 0.6749 - val_acc: 0.6333\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5749 - acc: 0.7583 - val_loss: 0.6726 - val_acc: 0.6333\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5723 - acc: 0.7583 - val_loss: 0.6704 - val_acc: 0.6333\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5698 - acc: 0.7583 - val_loss: 0.6682 - val_acc: 0.6333\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5672 - acc: 0.7583 - val_loss: 0.6659 - val_acc: 0.6333\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5647 - acc: 0.7583 - val_loss: 0.6636 - val_acc: 0.6333\n",
      "Epoch 166/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5623 - acc: 0.7583 - val_loss: 0.6615 - val_acc: 0.6667\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5598 - acc: 0.7583 - val_loss: 0.6594 - val_acc: 0.6667\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5574 - acc: 0.7583 - val_loss: 0.6572 - val_acc: 0.6667\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5551 - acc: 0.7583 - val_loss: 0.6552 - val_acc: 0.6667\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5526 - acc: 0.7583 - val_loss: 0.6530 - val_acc: 0.6667\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5504 - acc: 0.7583 - val_loss: 0.6509 - val_acc: 0.6667\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.5480 - acc: 0.7667 - val_loss: 0.6489 - val_acc: 0.6667\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5458 - acc: 0.7667 - val_loss: 0.6469 - val_acc: 0.6667\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5436 - acc: 0.7667 - val_loss: 0.6451 - val_acc: 0.6667\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5412 - acc: 0.7667 - val_loss: 0.6430 - val_acc: 0.6667\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5390 - acc: 0.7750 - val_loss: 0.6410 - val_acc: 0.6667\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5369 - acc: 0.7833 - val_loss: 0.6390 - val_acc: 0.6667\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5347 - acc: 0.7833 - val_loss: 0.6371 - val_acc: 0.6667\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5326 - acc: 0.7833 - val_loss: 0.6353 - val_acc: 0.6667\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.5305 - acc: 0.7833 - val_loss: 0.6335 - val_acc: 0.6667\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5284 - acc: 0.7833 - val_loss: 0.6316 - val_acc: 0.6667\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.5264 - acc: 0.7833 - val_loss: 0.6299 - val_acc: 0.6667\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5244 - acc: 0.7833 - val_loss: 0.6282 - val_acc: 0.6667\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5223 - acc: 0.7833 - val_loss: 0.6264 - val_acc: 0.6667\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5203 - acc: 0.7833 - val_loss: 0.6246 - val_acc: 0.6667\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5184 - acc: 0.7833 - val_loss: 0.6228 - val_acc: 0.6667\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5164 - acc: 0.7917 - val_loss: 0.6210 - val_acc: 0.6667\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5145 - acc: 0.7917 - val_loss: 0.6193 - val_acc: 0.6667\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5126 - acc: 0.7917 - val_loss: 0.6176 - val_acc: 0.6667\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5107 - acc: 0.7917 - val_loss: 0.6158 - val_acc: 0.6667\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5089 - acc: 0.7917 - val_loss: 0.6141 - val_acc: 0.6667\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5070 - acc: 0.7917 - val_loss: 0.6125 - val_acc: 0.6667\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5052 - acc: 0.7917 - val_loss: 0.6109 - val_acc: 0.6667\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.5034 - acc: 0.8083 - val_loss: 0.6093 - val_acc: 0.7000\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5016 - acc: 0.8083 - val_loss: 0.6077 - val_acc: 0.7000\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4998 - acc: 0.8083 - val_loss: 0.6062 - val_acc: 0.7000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4981 - acc: 0.8083 - val_loss: 0.6046 - val_acc: 0.7000\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4965 - acc: 0.8083 - val_loss: 0.6030 - val_acc: 0.7000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4947 - acc: 0.8083 - val_loss: 0.6014 - val_acc: 0.7000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4930 - acc: 0.8083 - val_loss: 0.6000 - val_acc: 0.7000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4914 - acc: 0.8083 - val_loss: 0.5986 - val_acc: 0.7000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4897 - acc: 0.8083 - val_loss: 0.5971 - val_acc: 0.7000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4881 - acc: 0.8083 - val_loss: 0.5958 - val_acc: 0.7000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4864 - acc: 0.8083 - val_loss: 0.5943 - val_acc: 0.7000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4848 - acc: 0.8083 - val_loss: 0.5929 - val_acc: 0.7000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4834 - acc: 0.8083 - val_loss: 0.5914 - val_acc: 0.7000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4986 - acc: 0.781 - 0s 117us/sample - loss: 0.4817 - acc: 0.8083 - val_loss: 0.5901 - val_acc: 0.7000\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4802 - acc: 0.8083 - val_loss: 0.5887 - val_acc: 0.7000\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4786 - acc: 0.8167 - val_loss: 0.5874 - val_acc: 0.7000\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4771 - acc: 0.8167 - val_loss: 0.5861 - val_acc: 0.7000\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4756 - acc: 0.8167 - val_loss: 0.5848 - val_acc: 0.7000\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.4741 - acc: 0.8167 - val_loss: 0.5834 - val_acc: 0.7000\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4727 - acc: 0.8250 - val_loss: 0.5821 - val_acc: 0.7000\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4712 - acc: 0.8250 - val_loss: 0.5809 - val_acc: 0.7000\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4697 - acc: 0.8250 - val_loss: 0.5797 - val_acc: 0.7000\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4683 - acc: 0.8250 - val_loss: 0.5785 - val_acc: 0.7000\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4669 - acc: 0.8250 - val_loss: 0.5774 - val_acc: 0.7000\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4655 - acc: 0.8250 - val_loss: 0.5762 - val_acc: 0.7000\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4641 - acc: 0.8250 - val_loss: 0.5750 - val_acc: 0.7000\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4628 - acc: 0.8250 - val_loss: 0.5738 - val_acc: 0.7000\n",
      "Epoch 221/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4614 - acc: 0.8250 - val_loss: 0.5727 - val_acc: 0.7000\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4601 - acc: 0.8250 - val_loss: 0.5716 - val_acc: 0.7000\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4588 - acc: 0.8250 - val_loss: 0.5704 - val_acc: 0.7000\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4574 - acc: 0.8250 - val_loss: 0.5692 - val_acc: 0.7000\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4561 - acc: 0.8417 - val_loss: 0.5681 - val_acc: 0.7000\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4549 - acc: 0.8333 - val_loss: 0.5671 - val_acc: 0.7000\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.4535 - acc: 0.8417 - val_loss: 0.5659 - val_acc: 0.7000\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4523 - acc: 0.8417 - val_loss: 0.5648 - val_acc: 0.7000\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4510 - acc: 0.8417 - val_loss: 0.5636 - val_acc: 0.7000\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4498 - acc: 0.8417 - val_loss: 0.5626 - val_acc: 0.7000\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4485 - acc: 0.8417 - val_loss: 0.5615 - val_acc: 0.7000\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4473 - acc: 0.8500 - val_loss: 0.5605 - val_acc: 0.7000\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4461 - acc: 0.8500 - val_loss: 0.5594 - val_acc: 0.7000\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4450 - acc: 0.8500 - val_loss: 0.5582 - val_acc: 0.7000\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4436 - acc: 0.8667 - val_loss: 0.5572 - val_acc: 0.7000\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4425 - acc: 0.8667 - val_loss: 0.5561 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4413 - acc: 0.8667 - val_loss: 0.5551 - val_acc: 0.7000\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4402 - acc: 0.8667 - val_loss: 0.5542 - val_acc: 0.7000\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4390 - acc: 0.8667 - val_loss: 0.5533 - val_acc: 0.7000\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4379 - acc: 0.8667 - val_loss: 0.5523 - val_acc: 0.7000\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4367 - acc: 0.8667 - val_loss: 0.5514 - val_acc: 0.7000\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4356 - acc: 0.8667 - val_loss: 0.5505 - val_acc: 0.7000\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4346 - acc: 0.8667 - val_loss: 0.5496 - val_acc: 0.7000\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4335 - acc: 0.8667 - val_loss: 0.5487 - val_acc: 0.7000\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4324 - acc: 0.8667 - val_loss: 0.5477 - val_acc: 0.7000\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4313 - acc: 0.8667 - val_loss: 0.5468 - val_acc: 0.7000\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4303 - acc: 0.8667 - val_loss: 0.5458 - val_acc: 0.7000\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4292 - acc: 0.8667 - val_loss: 0.5450 - val_acc: 0.7000\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4282 - acc: 0.8667 - val_loss: 0.5441 - val_acc: 0.7000\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4272 - acc: 0.8667 - val_loss: 0.5432 - val_acc: 0.7333\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.4261 - acc: 0.8667 - val_loss: 0.5423 - val_acc: 0.7333\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4251 - acc: 0.8667 - val_loss: 0.5414 - val_acc: 0.7333\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4241 - acc: 0.8667 - val_loss: 0.5405 - val_acc: 0.7333\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.4231 - acc: 0.8667 - val_loss: 0.5397 - val_acc: 0.7333\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4221 - acc: 0.8667 - val_loss: 0.5388 - val_acc: 0.7333\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4212 - acc: 0.8667 - val_loss: 0.5379 - val_acc: 0.7667\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4202 - acc: 0.8667 - val_loss: 0.5371 - val_acc: 0.7667\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4192 - acc: 0.8667 - val_loss: 0.5363 - val_acc: 0.7667\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4183 - acc: 0.8667 - val_loss: 0.5355 - val_acc: 0.7667\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4173 - acc: 0.8667 - val_loss: 0.5347 - val_acc: 0.7667\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4164 - acc: 0.8667 - val_loss: 0.5339 - val_acc: 0.7667\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.4155 - acc: 0.8667 - val_loss: 0.5330 - val_acc: 0.7667\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4145 - acc: 0.8667 - val_loss: 0.5323 - val_acc: 0.7667\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4136 - acc: 0.8667 - val_loss: 0.5314 - val_acc: 0.7667\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4127 - acc: 0.8667 - val_loss: 0.5306 - val_acc: 0.7667\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.4118 - acc: 0.8667 - val_loss: 0.5298 - val_acc: 0.7667\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4109 - acc: 0.8667 - val_loss: 0.5291 - val_acc: 0.7667\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4100 - acc: 0.8667 - val_loss: 0.5284 - val_acc: 0.7667\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.4091 - acc: 0.8667 - val_loss: 0.5276 - val_acc: 0.7667\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.4082 - acc: 0.8667 - val_loss: 0.5269 - val_acc: 0.7667\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.4074 - acc: 0.8667 - val_loss: 0.5261 - val_acc: 0.7667\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.4065 - acc: 0.8667 - val_loss: 0.5254 - val_acc: 0.7667\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.4056 - acc: 0.8667 - val_loss: 0.5247 - val_acc: 0.7667\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.4048 - acc: 0.8667 - val_loss: 0.5239 - val_acc: 0.7667\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.4040 - acc: 0.8667 - val_loss: 0.5233 - val_acc: 0.7667\n",
      "Epoch 276/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4031 - acc: 0.8667 - val_loss: 0.5225 - val_acc: 0.7667\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4023 - acc: 0.8667 - val_loss: 0.5218 - val_acc: 0.7667\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.4014 - acc: 0.8667 - val_loss: 0.5212 - val_acc: 0.7667\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.4006 - acc: 0.8667 - val_loss: 0.5206 - val_acc: 0.7667\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.3998 - acc: 0.8667 - val_loss: 0.5199 - val_acc: 0.7667\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.3990 - acc: 0.8667 - val_loss: 0.5193 - val_acc: 0.7667\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.3982 - acc: 0.8667 - val_loss: 0.5186 - val_acc: 0.7667\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.3974 - acc: 0.8667 - val_loss: 0.5179 - val_acc: 0.8000\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.3966 - acc: 0.8667 - val_loss: 0.5171 - val_acc: 0.8000\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.3958 - acc: 0.8667 - val_loss: 0.5164 - val_acc: 0.8000\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.3950 - acc: 0.8667 - val_loss: 0.5157 - val_acc: 0.8000\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.3943 - acc: 0.8667 - val_loss: 0.5150 - val_acc: 0.8000\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.3935 - acc: 0.8750 - val_loss: 0.5144 - val_acc: 0.8000\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4156 - acc: 0.781 - 0s 125us/sample - loss: 0.3927 - acc: 0.8750 - val_loss: 0.5137 - val_acc: 0.8000\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.3920 - acc: 0.8750 - val_loss: 0.5131 - val_acc: 0.8000\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.3912 - acc: 0.8750 - val_loss: 0.5125 - val_acc: 0.8000\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.3905 - acc: 0.8750 - val_loss: 0.5120 - val_acc: 0.8000\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.3898 - acc: 0.8750 - val_loss: 0.5112 - val_acc: 0.8000\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.3890 - acc: 0.8750 - val_loss: 0.5105 - val_acc: 0.8000\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.3883 - acc: 0.8750 - val_loss: 0.5100 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.3875 - acc: 0.8833 - val_loss: 0.5094 - val_acc: 0.8000\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4346 - acc: 0.843 - 0s 133us/sample - loss: 0.3868 - acc: 0.8833 - val_loss: 0.5087 - val_acc: 0.8000\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.3860 - acc: 0.8833 - val_loss: 0.5081 - val_acc: 0.8000\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.3853 - acc: 0.8833 - val_loss: 0.5075 - val_acc: 0.8000\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.3846 - acc: 0.8833 - val_loss: 0.5069 - val_acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xce0bbb4fc8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, y=y_train, epochs=300, \n",
    "         validation_data=(scaled_X_test, y_test), callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.087049</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.101436</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.085380</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.099628</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.083681</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.098200</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.082124</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.096946</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.080528</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.095714</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.387495</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.509357</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.386762</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.508699</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.386048</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.508100</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.385324</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.507542</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.384608</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.506897</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss   val_acc\n",
       "0    1.087049  0.325000  1.101436  0.366667\n",
       "1    1.085380  0.325000  1.099628  0.366667\n",
       "2    1.083681  0.325000  1.098200  0.366667\n",
       "3    1.082124  0.325000  1.096946  0.366667\n",
       "4    1.080528  0.325000  1.095714  0.366667\n",
       "..        ...       ...       ...       ...\n",
       "295  0.387495  0.883333  0.509357  0.800000\n",
       "296  0.386762  0.883333  0.508699  0.800000\n",
       "297  0.386048  0.883333  0.508100  0.800000\n",
       "298  0.385324  0.883333  0.507542  0.800000\n",
       "299  0.384608  0.883333  0.506897  0.800000\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 527us/sample - loss: 1.1696 - acc: 0.3400\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 1.1595 - acc: 0.3400\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.1502 - acc: 0.3600\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.1402 - acc: 0.3800\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.1316 - acc: 0.3867\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.1220 - acc: 0.4133\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.1134 - acc: 0.4533\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.1049 - acc: 0.5333\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0969 - acc: 0.5800\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0889 - acc: 0.6200\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0811 - acc: 0.6533\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0739 - acc: 0.6600\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0663 - acc: 0.6600\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0586 - acc: 0.6600\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0518 - acc: 0.6600\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0453 - acc: 0.6600\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 1.0376 - acc: 0.6600\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0312 - acc: 0.6533\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0242 - acc: 0.6333\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0174 - acc: 0.6400\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0111 - acc: 0.6400\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0046 - acc: 0.6400\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9980 - acc: 0.6333\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9915 - acc: 0.6267\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9846 - acc: 0.6333\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9780 - acc: 0.6267\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9706 - acc: 0.6133\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9632 - acc: 0.6267\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9570 - acc: 0.6333\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9508 - acc: 0.6400\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9451 - acc: 0.6533\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9392 - acc: 0.6533\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9333 - acc: 0.6600\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9277 - acc: 0.7067\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9217 - acc: 0.7467\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9162 - acc: 0.7733\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9104 - acc: 0.7733\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9049 - acc: 0.7667\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8994 - acc: 0.7733\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8941 - acc: 0.7867\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8881 - acc: 0.7800\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8828 - acc: 0.7867\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8774 - acc: 0.7667\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8719 - acc: 0.7533\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8667 - acc: 0.7333\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8614 - acc: 0.7200\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8559 - acc: 0.7067\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8507 - acc: 0.7067\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8455 - acc: 0.7067\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8404 - acc: 0.7133\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.8352 - acc: 0.7133\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8301 - acc: 0.7133\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8250 - acc: 0.7133\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8201 - acc: 0.7133\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8151 - acc: 0.7067\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8101 - acc: 0.7133\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8051 - acc: 0.7133\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8002 - acc: 0.7133\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7954 - acc: 0.7133\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7906 - acc: 0.7067\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7858 - acc: 0.7000\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7809 - acc: 0.7000\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7762 - acc: 0.7000\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.7715 - acc: 0.7000\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7669 - acc: 0.7000\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7623 - acc: 0.6933\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7578 - acc: 0.6933\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7531 - acc: 0.6933\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7486 - acc: 0.6933\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7441 - acc: 0.6933\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7398 - acc: 0.6933\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7354 - acc: 0.6933\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.7310 - acc: 0.6933\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7267 - acc: 0.6933\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.7224 - acc: 0.6933\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7182 - acc: 0.6933\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7140 - acc: 0.6933\n",
      "Epoch 78/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7099 - acc: 0.6933\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7059 - acc: 0.6933\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7019 - acc: 0.6933\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6978 - acc: 0.6933\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6939 - acc: 0.6933\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6901 - acc: 0.6933\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6862 - acc: 0.6933\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6824 - acc: 0.6933\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6786 - acc: 0.6933\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6749 - acc: 0.6933\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6713 - acc: 0.6933\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6676 - acc: 0.6933\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6640 - acc: 0.6933\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6605 - acc: 0.6933\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6570 - acc: 0.6933\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6535 - acc: 0.7000\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6501 - acc: 0.7000\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6467 - acc: 0.7000\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6434 - acc: 0.7000\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6400 - acc: 0.7000\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6367 - acc: 0.7000\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6335 - acc: 0.7000\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6304 - acc: 0.7067\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6271 - acc: 0.7067\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6240 - acc: 0.7067\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6209 - acc: 0.7067\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6179 - acc: 0.7067\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6148 - acc: 0.7067\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6119 - acc: 0.7067\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6089 - acc: 0.7133\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6060 - acc: 0.7133\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6031 - acc: 0.7133\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6003 - acc: 0.7267\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5975 - acc: 0.7400\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5947 - acc: 0.7400\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5920 - acc: 0.7400\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5893 - acc: 0.7400\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5866 - acc: 0.7400\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5840 - acc: 0.7400\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5813 - acc: 0.7400\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5787 - acc: 0.7400\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5762 - acc: 0.7400\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5737 - acc: 0.7400\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5712 - acc: 0.7400\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5687 - acc: 0.7533\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5663 - acc: 0.7533\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5640 - acc: 0.7800\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5615 - acc: 0.7800\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5592 - acc: 0.7800\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5568 - acc: 0.7800\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5545 - acc: 0.7800\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5523 - acc: 0.7800\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5500 - acc: 0.7800\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5478 - acc: 0.7867\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5456 - acc: 0.7867\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5434 - acc: 0.7933\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5413 - acc: 0.7933\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5391 - acc: 0.8133\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5371 - acc: 0.8133\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5350 - acc: 0.8133\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5329 - acc: 0.8133\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5309 - acc: 0.8200\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5289 - acc: 0.8267\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5269 - acc: 0.8333\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5249 - acc: 0.8267\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5229 - acc: 0.8333\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5210 - acc: 0.8333\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5191 - acc: 0.8333\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5172 - acc: 0.8400\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5153 - acc: 0.8400\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5135 - acc: 0.8400\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5116 - acc: 0.8467\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5098 - acc: 0.8467\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5080 - acc: 0.8533\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5062 - acc: 0.8600\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5045 - acc: 0.8533\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5027 - acc: 0.8600\n",
      "Epoch 155/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5009 - acc: 0.8600\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4993 - acc: 0.8667\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4975 - acc: 0.8667\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4958 - acc: 0.8667\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4941 - acc: 0.8733\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4926 - acc: 0.8733\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4908 - acc: 0.8733\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4893 - acc: 0.8733\n",
      "Epoch 163/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4877 - acc: 0.8733\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4860 - acc: 0.8733\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4844 - acc: 0.8733\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4828 - acc: 0.8800\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4812 - acc: 0.8867\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4797 - acc: 0.8933\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4781 - acc: 0.9000\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4765 - acc: 0.9000\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4752 - acc: 0.9000\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4737 - acc: 0.9200\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4720 - acc: 0.9200\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4704 - acc: 0.9200\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4690 - acc: 0.9133\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4675 - acc: 0.9133\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4660 - acc: 0.9133\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4646 - acc: 0.9200\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4633 - acc: 0.9200\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4617 - acc: 0.9200\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4603 - acc: 0.9200\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4588 - acc: 0.9267\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4574 - acc: 0.9267\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4560 - acc: 0.9267\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4546 - acc: 0.9267\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4532 - acc: 0.9267\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4518 - acc: 0.9267\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4504 - acc: 0.9333\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4490 - acc: 0.9333\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4477 - acc: 0.9333\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4465 - acc: 0.9333\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4450 - acc: 0.9333\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4438 - acc: 0.9333\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4423 - acc: 0.9333\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4410 - acc: 0.9333\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4397 - acc: 0.9333\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4384 - acc: 0.9333\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4371 - acc: 0.9333\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4357 - acc: 0.9333\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4345 - acc: 0.9333\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4333 - acc: 0.9333\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4320 - acc: 0.9333\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4306 - acc: 0.9333\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4294 - acc: 0.9333\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4281 - acc: 0.9333\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4269 - acc: 0.9333\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4256 - acc: 0.9333\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4244 - acc: 0.9333\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4231 - acc: 0.9333\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4219 - acc: 0.9333\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4206 - acc: 0.9400\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4194 - acc: 0.9400\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4182 - acc: 0.9400\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4169 - acc: 0.9400\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4157 - acc: 0.9400\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4144 - acc: 0.9400\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4133 - acc: 0.9400\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4120 - acc: 0.9400\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4109 - acc: 0.9400\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4097 - acc: 0.9400\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4085 - acc: 0.9400\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4073 - acc: 0.9400\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4060 - acc: 0.9400\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4048 - acc: 0.9400\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4036 - acc: 0.9400\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4025 - acc: 0.9400\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4013 - acc: 0.9400\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4001 - acc: 0.9400\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3990 - acc: 0.9400\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3978 - acc: 0.9400\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3966 - acc: 0.9400\n",
      "Epoch 232/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3955 - acc: 0.9400\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3943 - acc: 0.9400\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3932 - acc: 0.9400\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3921 - acc: 0.9400\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3910 - acc: 0.9400\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3898 - acc: 0.9400\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3886 - acc: 0.9400\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3875 - acc: 0.9400\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3863 - acc: 0.9400\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3852 - acc: 0.9467\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3841 - acc: 0.9467\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3830 - acc: 0.9467\n",
      "Epoch 244/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3818 - acc: 0.9467\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3807 - acc: 0.9467\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3796 - acc: 0.9467\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3785 - acc: 0.9467\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3774 - acc: 0.9467\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3763 - acc: 0.9467\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3752 - acc: 0.9467\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3279 - acc: 0.968 - 0s 87us/sample - loss: 0.3741 - acc: 0.9467\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3730 - acc: 0.9467\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3719 - acc: 0.9467\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3708 - acc: 0.9467\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3697 - acc: 0.9533\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.3686 - acc: 0.9533\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3676 - acc: 0.9533\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3665 - acc: 0.9533\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3654 - acc: 0.9533\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3643 - acc: 0.9533\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3633 - acc: 0.9533\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3622 - acc: 0.9533\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3611 - acc: 0.9533\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3600 - acc: 0.9533\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3590 - acc: 0.9533\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3579 - acc: 0.9533\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3569 - acc: 0.9533\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3559 - acc: 0.9533\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3548 - acc: 0.9533\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3537 - acc: 0.9533\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3527 - acc: 0.9533\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3516 - acc: 0.9533\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3506 - acc: 0.9533\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3496 - acc: 0.9533\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3485 - acc: 0.9533\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3475 - acc: 0.9533\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3465 - acc: 0.9533\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3454 - acc: 0.9533\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3444 - acc: 0.9533\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3434 - acc: 0.9533\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3423 - acc: 0.9533\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3414 - acc: 0.9533\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3403 - acc: 0.9533\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3394 - acc: 0.9533\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3383 - acc: 0.9533\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3374 - acc: 0.9600\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3363 - acc: 0.9600\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3354 - acc: 0.9600\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3343 - acc: 0.9600\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3333 - acc: 0.9600\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3324 - acc: 0.9600\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3313 - acc: 0.9533\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3304 - acc: 0.9600\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3294 - acc: 0.9533\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3285 - acc: 0.9600\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.3274 - acc: 0.9600\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3264 - acc: 0.9600\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3256 - acc: 0.9600\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3245 - acc: 0.9600\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3234 - acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xce0b23e448>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X, y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BhagavanReddy\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\BhagavanReddy\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\BhagavanReddy\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "flower_model = load_model('final_iris_model.h5')\n",
    "flower_scaler = joblib.load('iris_scaler.pkl')\n",
    "\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    \n",
    "    s_len = sample_json['SepalLengthCm']\n",
    "    s_wid = sample_json['SepalWidthCm']\n",
    "    p_len = sample_json['PetalLengthCm']\n",
    "    p_wid = sample_json['PetalWidthCm']\n",
    "    \n",
    "    flower = [[s_len,s_wid, p_len,p_wid]]\n",
    "    classes = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "    flower = scaler.transform(flower)\n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
